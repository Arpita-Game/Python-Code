{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad97e40-8cc9-4d46-ba24-f715f6ef5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b50c2197-b824-4d89-9076-f4c4ecfd1d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\scs\\anaconda3\\anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\scs\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\scs\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\scs\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\scs\\anaconda3\\anaconda\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\scs\\anaconda3\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db243232-ab54-4999-9724-352c1241ea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\scs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9dafb83-dff2-46af-9cd6-e0ff6f29acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language. Organizations today have large volumes of voice and text data from various communication channels like emails, text messages, social media newsfeeds, video, audio, and more. They use NLP software to automatically process this data, analyze the intent or sentiment in the message, and respond in real time to human communication.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84ce0434-e5a1-406f-a768-453215d650cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language. Organizations today have large volumes of voice and text data from various communication channels like emails, text messages, social media newsfeeds, video, audio, and more. They use NLP software to automatically process this data, analyze the intent or sentiment in the message, and respond in real time to human communication.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "412efd2b-2b7f-44c7-be88-5132c612dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "536ac373-bf63-4432-a770-b9155cdd91a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a66fcdf-9638-403d-924e-8a35bf80d621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f513f2a6-9fb2-4ec2-9024-e2df0e67a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a machine learning technology that gives computers the ability to interpret, manipulate, and comprehend human language.\n",
      "Organizations today have large volumes of voice and text data from various communication channels like emails, text messages, social media newsfeeds, video, audio, and more.\n",
      "They use NLP software to automatically process this data, analyze the intent or sentiment in the message, and respond in real time to human communication.\n"
     ]
    }
   ],
   "source": [
    "for sentences in doc:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "164e0b9c-107a-4d4c-9d4d-910ddc24f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ac757a-c004-4ece-a4bc-cf112bb84094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'technology',\n",
       " 'that',\n",
       " 'gives',\n",
       " 'computers',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'manipulate',\n",
       " ',',\n",
       " 'and',\n",
       " 'comprehend',\n",
       " 'human',\n",
       " 'language',\n",
       " '.',\n",
       " 'Organizations',\n",
       " 'today',\n",
       " 'have',\n",
       " 'large',\n",
       " 'volumes',\n",
       " 'of',\n",
       " 'voice',\n",
       " 'and',\n",
       " 'text',\n",
       " 'data',\n",
       " 'from',\n",
       " 'various',\n",
       " 'communication',\n",
       " 'channels',\n",
       " 'like',\n",
       " 'emails',\n",
       " ',',\n",
       " 'text',\n",
       " 'messages',\n",
       " ',',\n",
       " 'social',\n",
       " 'media',\n",
       " 'newsfeeds',\n",
       " ',',\n",
       " 'video',\n",
       " ',',\n",
       " 'audio',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " '.',\n",
       " 'They',\n",
       " 'use',\n",
       " 'NLP',\n",
       " 'software',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'process',\n",
       " 'this',\n",
       " 'data',\n",
       " ',',\n",
       " 'analyze',\n",
       " 'the',\n",
       " 'intent',\n",
       " 'or',\n",
       " 'sentiment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'message',\n",
       " ',',\n",
       " 'and',\n",
       " 'respond',\n",
       " 'in',\n",
       " 'real',\n",
       " 'time',\n",
       " 'to',\n",
       " 'human',\n",
       " 'communication',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b823043-e623-4614-92d4-8763d16d3a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'machine', 'learning', 'technology', 'that', 'gives', 'computers', 'the', 'ability', 'to', 'interpret', ',', 'manipulate', ',', 'and', 'comprehend', 'human', 'language', '.']\n",
      "['Organizations', 'today', 'have', 'large', 'volumes', 'of', 'voice', 'and', 'text', 'data', 'from', 'various', 'communication', 'channels', 'like', 'emails', ',', 'text', 'messages', ',', 'social', 'media', 'newsfeeds', ',', 'video', ',', 'audio', ',', 'and', 'more', '.']\n",
      "['They', 'use', 'NLP', 'software', 'to', 'automatically', 'process', 'this', 'data', ',', 'analyze', 'the', 'intent', 'or', 'sentiment', 'in', 'the', 'message', ',', 'and', 'respond', 'in', 'real', 'time', 'to', 'human', 'communication', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentences in doc:\n",
    "    print(word_tokenize(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33ee14cc-52ac-4f03-b237-f0fdc3721633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a35ac58e-22f1-46c2-8135-052b3249d68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'machine', 'learning', 'technology', 'that', 'gives', 'computers', 'the', 'ability', 'to', 'interpret', ',', 'manipulate', ',', 'and', 'comprehend', 'human', 'language', '.']\n",
      "['Organizations', 'today', 'have', 'large', 'volumes', 'of', 'voice', 'and', 'text', 'data', 'from', 'various', 'communication', 'channels', 'like', 'emails', ',', 'text', 'messages', ',', 'social', 'media', 'newsfeeds', ',', 'video', ',', 'audio', ',', 'and', 'more', '.']\n",
      "['They', 'use', 'NLP', 'software', 'to', 'automatically', 'process', 'this', 'data', ',', 'analyze', 'the', 'intent', 'or', 'sentiment', 'in', 'the', 'message', ',', 'and', 'respond', 'in', 'real', 'time', 'to', 'human', 'communication', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentences in doc:\n",
    "    print(wordpunct_tokenize(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b146415-0d24-48d0-a09d-fbee1cde54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d4e05ba-6590-4d36-ac70-7bc9d80b156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "110ac2c1-73df-40fc-88a4-3cb81f8e1c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'technology',\n",
       " 'that',\n",
       " 'gives',\n",
       " 'computers',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'interpret',\n",
       " ',',\n",
       " 'manipulate',\n",
       " ',',\n",
       " 'and',\n",
       " 'comprehend',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'Organizations',\n",
       " 'today',\n",
       " 'have',\n",
       " 'large',\n",
       " 'volumes',\n",
       " 'of',\n",
       " 'voice',\n",
       " 'and',\n",
       " 'text',\n",
       " 'data',\n",
       " 'from',\n",
       " 'various',\n",
       " 'communication',\n",
       " 'channels',\n",
       " 'like',\n",
       " 'emails',\n",
       " ',',\n",
       " 'text',\n",
       " 'messages',\n",
       " ',',\n",
       " 'social',\n",
       " 'media',\n",
       " 'newsfeeds',\n",
       " ',',\n",
       " 'video',\n",
       " ',',\n",
       " 'audio',\n",
       " ',',\n",
       " 'and',\n",
       " 'more.',\n",
       " 'They',\n",
       " 'use',\n",
       " 'NLP',\n",
       " 'software',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'process',\n",
       " 'this',\n",
       " 'data',\n",
       " ',',\n",
       " 'analyze',\n",
       " 'the',\n",
       " 'intent',\n",
       " 'or',\n",
       " 'sentiment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'message',\n",
       " ',',\n",
       " 'and',\n",
       " 'respond',\n",
       " 'in',\n",
       " 'real',\n",
       " 'time',\n",
       " 'to',\n",
       " 'human',\n",
       " 'communication',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daeec9a1-c32f-47ad-9fff-d148505fd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming - Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "709b61fa-c70a-4ad2-9ed1-d8510e79ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb1cad2e-022c-431c-a821-4302121e35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['eat','eating','writting','writes','congratulations','eaten','history','berry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "508dd598-6837-4560-aa55-2838e3d69d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1e30fb0-df49-4d87-ba32-892516872642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat--->eat\n",
      "eating--->eat\n",
      "writting--->writ\n",
      "writes--->write\n",
      "congratulations--->congratul\n",
      "eaten--->eaten\n",
      "history--->histori\n",
      "berry--->berri\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'--->'+stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6a7e3c0-3f66-4340-9929-e62451102d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('lovely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e30f9385-bc7e-490f-a527-5600fc6f323d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organ'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('organization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28419c7a-0989-40c8-876b-807e8a743278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmer - Regexpstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0ef7f91-b50c-49dd-87a8-ef6e491ed875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ff820cc-495c-4ba7-ab54-59216745a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64048904-9dcf-4770-9740-79cea1115d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'show'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('showing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "050404f3-5134-4f91-95db-1da12b47eee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fashion'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('Fashionable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa1cae5c-4787-4ea6-9ff4-a871f71852dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eye'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('eye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9eacb7fc-582c-4421-b670-114e0951061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemmer- Snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3393cec-cb20-4557-92bf-2739ca949d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "861722e4-11ff-492e-8246-48aa49f9a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S= SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86d211f1-423a-4cc8-89b3-c1c33f2d71b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fair'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.stem('Fairly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3766e418-2a5c-4635-b4a3-67f13571eed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairli'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('Fairly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15b3e5cc-dd1c-4f58-a226-e43e563aa69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fairly'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('Fairly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51219aec-25e4-49bc-9301-93942f692c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histor'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.stem('Historically')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "27f6e7c9-5042-4904-bad8-7f9a5abf3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c7c3564-bda0-4f2e-8728-154ce3d61978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\scs\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0aa289e1-dbdb-4cd6-b0f2-963b5c084481",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dae827e0-19dc-4b77-86d1-31a3257faaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad995e22-2947-4d80-b25c-633b63c7ee8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9ac5d2a6-b319-4c9e-b7a1-183dca833896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eating---->eat\n",
      "writting---->writting\n",
      "writes---->write\n",
      "congratulations---->congratulations\n",
      "eaten---->eat\n",
      "history---->history\n",
      "berry---->berry\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52a43e-d808-48a1-8571-ca78f99d96d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
